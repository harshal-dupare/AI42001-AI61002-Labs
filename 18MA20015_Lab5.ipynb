{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Harshal Dupare | 18MA20015 | LAB 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Classification of Sentences using Na√Øve Bayes\n",
    "You are given a dataset where every sentence is marked as 0 (negative) and 1 (positive). The tag\n",
    "indicates whether the sentence is carrying a positive or negative sentiment. Your task is to classify the\n",
    "sentences in these two categories using Na√Øve Bayes classifier.\n",
    "\n",
    "The feature value of a word in a sentence is defined by log(1 + ùë°ùëì) ‚àó log(ùëÅ/ùëëùëì), where tf denotes\n",
    "the count of the word in the sentence, N is the total number of sentences in the training data and df\n",
    "denotes the number of sentences in the training data that contains the word.\n",
    "\n",
    "Dataset link: https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences and then go to\n",
    "data folder and download .zip file.\n",
    "\n",
    "Note: There are three different datasets in the zip folder. You need to merge them to create a single\n",
    "dataset. Then use 80% of the data as training set and rest as test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "eng_stopwords = stopwords.words('english')\n",
    "snowball_stemmer = SnowballStemmer(language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.txt',sep='\\t',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regular expression for preprocessing the input to remove strings which are not words\n",
    "res = r'<.*?>|http\\S+|www\\S+|[^a-zA-Z\\s]|\\n'\n",
    "reprocess = re.compile(res)\n",
    "df[0] = df[0].apply(lambda x: re.sub(reprocess, '', x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing stopwords and applying stemming and lemmaitization\n",
    "df[0] = df[0].apply(lambda x: snowball_stemmer.stem(' '.join([w for w in word_tokenize(x) if w not in eng_stopwords])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['celebration',\n",
       " 'sources',\n",
       " 'nutshell',\n",
       " 'construct',\n",
       " 'generous',\n",
       " 'touch',\n",
       " 'noises',\n",
       " 'write',\n",
       " 'shield',\n",
       " 'nan']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus =\" \"\n",
    "for s in df[0]:\n",
    "    corpus+=' '+s\n",
    "wordset = list(set(corpus.split(' ')))[1:]\n",
    "print(len(wordset))\n",
    "wordset[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df.iloc[:,1:]\n",
    "N = len(y)\n",
    "wordfreq = FreqDist(corpus.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame()\n",
    "#  cwf[\"w\"] denotes the number of sentences in the training data that contains the word \"w\"\n",
    "cwf = dict()\n",
    "\n",
    "for w in wordset:\n",
    "    X[w]=np.zeros(N,dtype=np.float64)\n",
    "    cwf[w]=0\n",
    "\n",
    "for i in range(N):\n",
    "    wst =set(df.iloc[i,0].split(' '))\n",
    "    for temp in wst:\n",
    "        if temp!='':\n",
    "            cwf[temp]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making the dataframe and features\n",
    "for i in range(N):\n",
    "    st = df.iloc[i,0]\n",
    "    fst = FreqDist(st.split(' '))\n",
    "    for sw in fst:\n",
    "        if sw != '':\n",
    "            X[sw][i]=np.log(N/cwf[sw])*np.log(1+fst[sw])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>celebration</th>\n",
       "      <th>sources</th>\n",
       "      <th>nutshell</th>\n",
       "      <th>construct</th>\n",
       "      <th>generous</th>\n",
       "      <th>touch</th>\n",
       "      <th>noises</th>\n",
       "      <th>write</th>\n",
       "      <th>shield</th>\n",
       "      <th>nan</th>\n",
       "      <th>...</th>\n",
       "      <th>anyone</th>\n",
       "      <th>official</th>\n",
       "      <th>tend</th>\n",
       "      <th>sangria</th>\n",
       "      <th>lately</th>\n",
       "      <th>seemed</th>\n",
       "      <th>trying</th>\n",
       "      <th>frustration</th>\n",
       "      <th>eyepleasing</th>\n",
       "      <th>ps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2748.000000</td>\n",
       "      <td>2748.000000</td>\n",
       "      <td>2748.000000</td>\n",
       "      <td>2748.000000</td>\n",
       "      <td>2748.000000</td>\n",
       "      <td>2748.000000</td>\n",
       "      <td>2748.000000</td>\n",
       "      <td>2748.000000</td>\n",
       "      <td>2748.000000</td>\n",
       "      <td>2748.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2748.000000</td>\n",
       "      <td>2748.000000</td>\n",
       "      <td>2748.000000</td>\n",
       "      <td>2748.000000</td>\n",
       "      <td>2748.000000</td>\n",
       "      <td>2748.000000</td>\n",
       "      <td>2748.000000</td>\n",
       "      <td>2748.000000</td>\n",
       "      <td>2748.000000</td>\n",
       "      <td>2748.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.001997</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>0.003645</td>\n",
       "      <td>0.005161</td>\n",
       "      <td>0.007957</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>0.004711</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022830</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>0.009273</td>\n",
       "      <td>0.012988</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>0.001997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.104705</td>\n",
       "      <td>0.104705</td>\n",
       "      <td>0.104705</td>\n",
       "      <td>0.135089</td>\n",
       "      <td>0.156137</td>\n",
       "      <td>0.186406</td>\n",
       "      <td>0.104705</td>\n",
       "      <td>0.179018</td>\n",
       "      <td>0.104705</td>\n",
       "      <td>0.104705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.281205</td>\n",
       "      <td>0.104705</td>\n",
       "      <td>0.104705</td>\n",
       "      <td>0.104705</td>\n",
       "      <td>0.104705</td>\n",
       "      <td>0.198260</td>\n",
       "      <td>0.226625</td>\n",
       "      <td>0.104705</td>\n",
       "      <td>0.104705</td>\n",
       "      <td>0.104705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.488775</td>\n",
       "      <td>5.488775</td>\n",
       "      <td>5.488775</td>\n",
       "      <td>5.008322</td>\n",
       "      <td>4.727275</td>\n",
       "      <td>4.373198</td>\n",
       "      <td>5.488775</td>\n",
       "      <td>7.938003</td>\n",
       "      <td>5.488775</td>\n",
       "      <td>5.488775</td>\n",
       "      <td>...</td>\n",
       "      <td>3.485322</td>\n",
       "      <td>5.488775</td>\n",
       "      <td>5.488775</td>\n",
       "      <td>5.488775</td>\n",
       "      <td>5.488775</td>\n",
       "      <td>4.246822</td>\n",
       "      <td>3.965775</td>\n",
       "      <td>5.488775</td>\n",
       "      <td>5.488775</td>\n",
       "      <td>5.488775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows √ó 5429 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       celebration      sources     nutshell    construct     generous  \\\n",
       "count  2748.000000  2748.000000  2748.000000  2748.000000  2748.000000   \n",
       "mean      0.001997     0.001997     0.001997     0.003645     0.005161   \n",
       "std       0.104705     0.104705     0.104705     0.135089     0.156137   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       5.488775     5.488775     5.488775     5.008322     4.727275   \n",
       "\n",
       "             touch       noises        write       shield          nan  ...  \\\n",
       "count  2748.000000  2748.000000  2748.000000  2748.000000  2748.000000  ...   \n",
       "mean      0.007957     0.001997     0.004711     0.001997     0.001997  ...   \n",
       "std       0.186406     0.104705     0.179018     0.104705     0.104705  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "max       4.373198     5.488775     7.938003     5.488775     5.488775  ...   \n",
       "\n",
       "            anyone     official         tend      sangria       lately  \\\n",
       "count  2748.000000  2748.000000  2748.000000  2748.000000  2748.000000   \n",
       "mean      0.022830     0.001997     0.001997     0.001997     0.001997   \n",
       "std       0.281205     0.104705     0.104705     0.104705     0.104705   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       3.485322     5.488775     5.488775     5.488775     5.488775   \n",
       "\n",
       "            seemed       trying  frustration  eyepleasing           ps  \n",
       "count  2748.000000  2748.000000  2748.000000  2748.000000  2748.000000  \n",
       "mean      0.009273     0.012988     0.001997     0.001997     0.001997  \n",
       "std       0.198260     0.226625     0.104705     0.104705     0.104705  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "max       4.246822     3.965775     5.488775     5.488775     5.488775  \n",
       "\n",
       "[8 rows x 5429 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the given dataset is a Balanced dataset\n"
     ]
    }
   ],
   "source": [
    "y.hist(grid=False)\n",
    "plt.title(\"Class histogram\")\n",
    "plt.show()\n",
    "print(\"the given dataset is a Balanced dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harshal d\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.48      0.57       272\n",
      "           1       0.61      0.81      0.70       278\n",
      "\n",
      "    accuracy                           0.65       550\n",
      "   macro avg       0.66      0.65      0.64       550\n",
      "weighted avg       0.66      0.65      0.64       550\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = gnb.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2\n",
    "\n",
    "I believe this is the correct method as it assumes the same word frequency distribution for test data as we used for training. But as it was not specified I have done both the methods\n",
    "\n",
    "* In this method we process test data based on the frequency we get on the training data ( assuming same distribution )\n",
    "* The previous method has some information about the test set as it is incorporated in the train set frequency calculations, whereas this method doesn't have such bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_train_dataset(data):\n",
    "\n",
    "    # regular expression for preprocessing the input to remove strings which are not words\n",
    "    res = r'<.*?>|http\\S+|www\\S+|[^a-zA-Z\\s]|\\n'\n",
    "    reprocess = re.compile(res)\n",
    "    data[0] = data[0].apply(lambda x: re.sub(reprocess, '', x.lower()))\n",
    "    \n",
    "    # removing stopwords and applying stemming and lemmaitization\n",
    "    data[0] = data[0].apply(lambda x: snowball_stemmer.stem(' '.join([w for w in word_tokenize(x) if w not in eng_stopwords])))\n",
    "    \n",
    "    data_corpus =\" \"\n",
    "    for s in data[0]:\n",
    "        data_corpus+=' '+s\n",
    "    data_wordset = list(set(data_corpus.split(' ')))\n",
    "    \n",
    "    data_y=data.iloc[:,1:]\n",
    "    data_N = len(data_y)\n",
    "    data_X = pd.DataFrame()\n",
    "    \n",
    "    #  data_cwf[\"w\"] denotes the number of sentences in the training data that contains the word \"w\"\n",
    "    data_cwf = dict()\n",
    "\n",
    "    for w in data_wordset:\n",
    "        if w!='':\n",
    "            data_X[w]=np.zeros(data_N,dtype=np.float64)\n",
    "            data_cwf[w]=0\n",
    "\n",
    "    for i in range(data_N):\n",
    "        wst =set(data.iloc[i,0].split(' '))\n",
    "        for temp in wst:\n",
    "            if temp!='':\n",
    "                data_cwf[temp]+=1\n",
    "\n",
    "    # making the dataframe and features\n",
    "    for i in range(data_N):\n",
    "        st = data.iloc[i,0]\n",
    "        fst = FreqDist(st.split(' '))\n",
    "        for sw in fst:\n",
    "            if sw != '':\n",
    "                data_X[sw][i]=np.log(data_N/data_cwf[sw])*np.log(1+fst[sw])\n",
    "                \n",
    "    return data_X,data_y,data_wordset,data_cwf\n",
    "\n",
    "def process_test_dataset(data,train_wordset,train_N,train_cwf):\n",
    "\n",
    "    # regular expression for preprocessing the input to remove strings which are not words\n",
    "    res = r'<.*?>|http\\S+|www\\S+|[^a-zA-Z\\s]|\\n'\n",
    "    reprocess = re.compile(res)\n",
    "    data[0] = data[0].apply(lambda x: re.sub(reprocess, '', x.lower()))\n",
    "    \n",
    "    # removing stopwords and applying stemming and lemmaitization\n",
    "    data[0] = data[0].apply(lambda x: snowball_stemmer.stem(' '.join([w for w in word_tokenize(x) if w not in eng_stopwords])))\n",
    "    \n",
    "    data_y=data.iloc[:,1:]\n",
    "    data_N = len(data_y)\n",
    "    data_X = pd.DataFrame()\n",
    "\n",
    "    for w in train_wordset:\n",
    "        if w!='':\n",
    "            data_X[w]=np.zeros(data_N,dtype=np.float64)\n",
    "\n",
    "    # making the dataframe and features\n",
    "    for i in range(data_N):\n",
    "        st = data.iloc[i,0]\n",
    "        fst = FreqDist(st.split(' '))\n",
    "        for sw in fst:\n",
    "            if sw != '' and sw in train_wordset:\n",
    "                data_X[sw][i]=np.log(train_N/train_cwf[sw])*np.log(1+fst[sw])\n",
    "                \n",
    "    return data_X,data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.txt',sep='\\t',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfy = df.iloc[:,1:]\n",
    "df_train, df_test,_,_ = train_test_split(df, dfy, test_size=0.20, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.reset_index().drop(columns=['index'])\n",
    "df_test = df_test.reset_index().drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train,wordset_train,cwf_train = process_train_dataset(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>regardless</th>\n",
       "      <th>believed</th>\n",
       "      <th>originally</th>\n",
       "      <th>derivative</th>\n",
       "      <th>saganaki</th>\n",
       "      <th>shell</th>\n",
       "      <th>goat</th>\n",
       "      <th>delivers</th>\n",
       "      <th>sources</th>\n",
       "      <th>celebration</th>\n",
       "      <th>...</th>\n",
       "      <th>intelligent</th>\n",
       "      <th>cuisin</th>\n",
       "      <th>finished</th>\n",
       "      <th>babbling</th>\n",
       "      <th>pink</th>\n",
       "      <th>feet</th>\n",
       "      <th>interview</th>\n",
       "      <th>grace</th>\n",
       "      <th>forgot</th>\n",
       "      <th>take</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2198.000000</td>\n",
       "      <td>2198.000000</td>\n",
       "      <td>2198.000000</td>\n",
       "      <td>2198.000000</td>\n",
       "      <td>2198.000000</td>\n",
       "      <td>2198.000000</td>\n",
       "      <td>2198.000000</td>\n",
       "      <td>2198.000000</td>\n",
       "      <td>2198.000000</td>\n",
       "      <td>2198.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2198.000000</td>\n",
       "      <td>2198.000000</td>\n",
       "      <td>2198.000000</td>\n",
       "      <td>2198.000000</td>\n",
       "      <td>2198.000000</td>\n",
       "      <td>2198.000000</td>\n",
       "      <td>2198.000000</td>\n",
       "      <td>2198.000000</td>\n",
       "      <td>2198.000000</td>\n",
       "      <td>2198.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.006241</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006241</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.004416</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.006241</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.004416</td>\n",
       "      <td>0.004416</td>\n",
       "      <td>0.024838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.113773</td>\n",
       "      <td>0.113773</td>\n",
       "      <td>0.113773</td>\n",
       "      <td>0.113773</td>\n",
       "      <td>0.113773</td>\n",
       "      <td>0.113773</td>\n",
       "      <td>0.113773</td>\n",
       "      <td>0.168850</td>\n",
       "      <td>0.113773</td>\n",
       "      <td>0.113773</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168850</td>\n",
       "      <td>0.113773</td>\n",
       "      <td>0.146373</td>\n",
       "      <td>0.113773</td>\n",
       "      <td>0.113773</td>\n",
       "      <td>0.168850</td>\n",
       "      <td>0.113773</td>\n",
       "      <td>0.146373</td>\n",
       "      <td>0.146373</td>\n",
       "      <td>0.290127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.333978</td>\n",
       "      <td>5.333978</td>\n",
       "      <td>5.333978</td>\n",
       "      <td>5.333978</td>\n",
       "      <td>5.333978</td>\n",
       "      <td>5.333978</td>\n",
       "      <td>5.333978</td>\n",
       "      <td>4.572478</td>\n",
       "      <td>5.333978</td>\n",
       "      <td>5.333978</td>\n",
       "      <td>...</td>\n",
       "      <td>4.572478</td>\n",
       "      <td>5.333978</td>\n",
       "      <td>4.853525</td>\n",
       "      <td>5.333978</td>\n",
       "      <td>5.333978</td>\n",
       "      <td>4.572478</td>\n",
       "      <td>5.333978</td>\n",
       "      <td>4.853525</td>\n",
       "      <td>4.853525</td>\n",
       "      <td>3.412166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows √ó 4700 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        regardless     believed   originally   derivative     saganaki  \\\n",
       "count  2198.000000  2198.000000  2198.000000  2198.000000  2198.000000   \n",
       "mean      0.002427     0.002427     0.002427     0.002427     0.002427   \n",
       "std       0.113773     0.113773     0.113773     0.113773     0.113773   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       5.333978     5.333978     5.333978     5.333978     5.333978   \n",
       "\n",
       "             shell         goat     delivers      sources  celebration  ...  \\\n",
       "count  2198.000000  2198.000000  2198.000000  2198.000000  2198.000000  ...   \n",
       "mean      0.002427     0.002427     0.006241     0.002427     0.002427  ...   \n",
       "std       0.113773     0.113773     0.168850     0.113773     0.113773  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "max       5.333978     5.333978     4.572478     5.333978     5.333978  ...   \n",
       "\n",
       "       intelligent       cuisin     finished     babbling         pink  \\\n",
       "count  2198.000000  2198.000000  2198.000000  2198.000000  2198.000000   \n",
       "mean      0.006241     0.002427     0.004416     0.002427     0.002427   \n",
       "std       0.168850     0.113773     0.146373     0.113773     0.113773   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       4.572478     5.333978     4.853525     5.333978     5.333978   \n",
       "\n",
       "              feet    interview        grace       forgot         take  \n",
       "count  2198.000000  2198.000000  2198.000000  2198.000000  2198.000000  \n",
       "mean      0.006241     0.002427     0.004416     0.004416     0.024838  \n",
       "std       0.168850     0.113773     0.146373     0.146373     0.290127  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "max       4.572478     5.333978     4.853525     4.853525     3.412166  \n",
       "\n",
       "[8 rows x 4700 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can observe that the number of columns are less as the dataset is only 80% hence we missout on some of the words\n",
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harshal d\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,y_test = process_test_dataset(df_test,wordset_train,len(y_train),cwf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.47      0.56       272\n",
      "           1       0.61      0.81      0.69       278\n",
      "\n",
      "    accuracy                           0.64       550\n",
      "   macro avg       0.66      0.64      0.63       550\n",
      "weighted avg       0.66      0.64      0.63       550\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# we can observe nearly same performance of the method 2\n",
    "# but it is just 1% less, which maybe due to it doesn't have that bias of knowing the frequency in test set\n",
    "y_pred = gnb.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
